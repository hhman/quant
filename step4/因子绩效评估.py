#!/usr/bin/env python3
"""
Step4: å› å­ç»©æ•ˆè¯„ä¼°
åŠŸèƒ½ï¼šå…¨é¢è¯„ä¼°å› å­æœ‰æ•ˆæ€§ï¼ˆICã€åˆ†ç»„æ”¶ç›Šã€è‡ªç›¸å…³ã€æ¢æ‰‹ç‡ç­‰ï¼‰
æ”¯æŒæ™ºèƒ½cacheå­é›†åŒ¹é…
ä¾èµ–qlibçš„ç»©æ•ˆè¯„ä¼°å‡½æ•°ï¼ˆcalc_ic, calc_long_short_return, pred_autocorrï¼‰
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import qlib
from qlib.constant import REG_CN

from utils.cache_manager import CacheManager
from core.factor_analysis import (
    summarize_ic,
    summarize_group_return,
    summarize_autocorr,
    summarize_turnover,
    save_performance_graphs,
)


def evaluate_performance(
    market: str,
    start_date: str,
    end_date: str,
    factor_formulas: list[str],
    provider_uri: str,
) -> None:
    """
    è¯„ä¼°å› å­ç»©æ•ˆçš„æ ¸å¿ƒé€»è¾‘å‡½æ•°

    Parameters:
    -----------
    market : str
        å¸‚åœºæ ‡è¯†
    start_date : str
        èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
    end_date : str
        ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    factor_formulas : list[str]
        å› å­è¡¨è¾¾å¼åˆ—è¡¨
    provider_uri : str
        Qlibæ•°æ®è·¯å¾„

    Returns:
    --------
    None
    """
    # åˆ›å»ºcacheç®¡ç†å™¨
    cache_mgr = CacheManager(market, start_date, end_date)

    # åˆå§‹åŒ–qlib
    print(f"ğŸ“Š åˆå§‹åŒ–Qlib: {provider_uri}")
    qlib.init(provider_uri=provider_uri, region=REG_CN)

    print("\nğŸ“ˆ Step4: å› å­ç»©æ•ˆè¯„ä¼°")

    # åŠ è½½æ•°æ®
    print("ğŸ“¥ åŠ è½½æ•°æ®...")
    factor_df = cache_mgr.read_dataframe("neutralized")
    print(f"  âœ“ å› å­æ•°æ®ï¼ˆä¸­æ€§åŒ–åï¼‰: {factor_df.shape}")

    ret_df = cache_mgr.read_dataframe("returns")
    print(f"  âœ“ æ”¶ç›Šç‡æ•°æ®: {ret_df.shape}")

    if factor_df.empty:
        print("âŒ é”™è¯¯: å› å­æ•°æ®ä¸ºç©º")
        print("   è¯·æ£€æŸ¥step2æ˜¯å¦æˆåŠŸç”Ÿæˆ")
        sys.exit(1)

    if ret_df.empty:
        print("âŒ é”™è¯¯: æ”¶ç›Šç‡æ•°æ®ä¸ºç©º")
        print("   è¯·æ£€æŸ¥step1æ˜¯å¦æˆåŠŸç”Ÿæˆ")
        sys.exit(1)

    # æ£€æŸ¥ç´¢å¼•ä¸€è‡´æ€§
    if factor_df.index.nlevels != 2 or ret_df.index.nlevels != 2:
        print("âŒ é”™è¯¯: æ•°æ®ç´¢å¼•æ ¼å¼ä¸æ­£ç¡®")
        print(f"   factor_dfç´¢å¼•: {factor_df.index.names}")
        print(f"   ret_dfç´¢å¼•: {ret_df.index.names}")
        print("   æœŸæœ›ç´¢å¼•: (instrument, datetime)")
        sys.exit(1)

    merged_df = factor_df.join(ret_df, how="left")
    factor_list = list(factor_df.columns)
    ret_list = list(ret_df.columns)

    # ä½¿ç”¨ç´§å‡‘æ—¥æœŸæ ¼å¼ä¿å­˜æ±‡æ€»æ–‡ä»¶
    start_compact = start_date.replace("-", "")
    end_compact = end_date.replace("-", "")

    # IC / RankICåˆ†æ
    print("âš™ï¸  è®¡ç®—IC/RankIC...")
    ic_df, ric_df, ic_summary, ric_summary = summarize_ic(
        merged_df, factor_list=factor_list, ret_list=ret_list
    )
    cache_mgr.write_dataframe(ic_df, "ic")
    cache_mgr.write_dataframe(ric_df, "rank_ic")
    ic_summary.to_excel(
        f".cache/{market}_{start_compact}_{end_compact}__ic_summary.xlsx", index=True
    )
    ric_summary.to_excel(
        f".cache/{market}_{start_compact}_{end_compact}__rank_ic_summary.xlsx",
        index=True,
    )
    print(f"  âœ“ ä¿å­˜: ic ({ic_df.shape}), rank_ic ({ric_df.shape})")

    # åˆ†ç»„æ”¶ç›Šåˆ†æ
    print("âš™ï¸  è®¡ç®—åˆ†ç»„æ”¶ç›Š...")
    group_daily_df, group_summary = summarize_group_return(
        merged_df,
        factor_list=factor_list,
        ret_list=ret_list,
        quantile=0.2,
    )
    cache_mgr.write_dataframe(group_daily_df, "group_return")
    group_summary.to_excel(
        f".cache/{market}_{start_compact}_{end_compact}__group_return_summary.xlsx",
        index=True,
    )
    print(f"  âœ“ ä¿å­˜: group_return ({group_daily_df.shape})")

    # è‡ªç›¸å…³åˆ†æ
    print("âš™ï¸  è®¡ç®—è‡ªç›¸å…³...")
    ac_df, ac_summary = summarize_autocorr(
        merged_df,
        factor_list=factor_list,
        lag=1,
    )
    cache_mgr.write_dataframe(ac_df, "autocorr")
    ac_summary.to_excel(
        f".cache/{market}_{start_compact}_{end_compact}__autocorr_summary.xlsx",
        index=True,
    )
    print(f"  âœ“ ä¿å­˜: autocorr ({ac_df.shape})")

    # æ¢æ‰‹ç‡åˆ†æ
    print("âš™ï¸  è®¡ç®—æ¢æ‰‹ç‡...")
    turnover_daily_df, turnover_summary = summarize_turnover(
        merged_df,
        factor_list=factor_list,
        N=5,
        lag=1,
    )
    cache_mgr.write_dataframe(turnover_daily_df, "turnover")
    turnover_summary.to_excel(
        f".cache/{market}_{start_compact}_{end_compact}__turnover_summary.xlsx",
        index=True,
    )
    print(f"  âœ“ ä¿å­˜: turnover ({turnover_daily_df.shape})")

    # ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨
    print("\nâš™ï¸  ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨...")
    try:
        graphs_dir = Path(".cache") / "graphs"
        save_performance_graphs(
            merged_df=merged_df,
            factor_list=factor_list,
            ret_list=ret_list,
            output_dir=graphs_dir,
            graph_names=["group_return", "pred_ic", "pred_autocorr", "pred_turnover"],
        )
        print(f"  âœ“ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {graphs_dir}")
    except Exception as e:
        print(f"  âš ï¸  ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        print("     è·³è¿‡å›¾è¡¨ç”Ÿæˆï¼Œç»§ç»­...")

    print("\nâœ… Step4å®Œæˆ!")
    print("   æ‰€æœ‰è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: .cache/")
